# myEcho
MyEcho는 Streamlit 기반의 대화형 AI 어시스턴트 웹 애플리케이션입니다.  
이 애플리케이션은 사용자의 질문에 대해 CSV 파일에서 정보를 검색하고, LLM 모델을 통해 답변을 제공합니다.

## 기간
- 2024.08.20. ~ 2024.08.23.

## 기술 스택
- Streamlit
- Ollama
- Pandas
- LangChain
- ChromaDB

## 운영 체제
- MacOS

## IDE
- Visual Studio Code

## 사용 방법 
```
# 1. Ollama 서버 시작 
ollama serve

# 2. main.py 실행
streamlit run main.py
```

## 주요 기능
1. 대화 기록 관리
    - Streamlit의 session_state를 활용하여 사용자의 질문과 AI의 응답을 저장합니다.
2. 문서 검색 및 정보 제공
    - Pandas를 사용하여 csv 파일에서 텍스트 데이터를 로드하고, LangChain의 Chroma 벡터 데이터베이스를 저장합니다. 사용자의 질문에 대해 벡터 검색을 통해 관련 정보를 추출합니다.
3. 프롬프트 구성
    - 벡터 DB에서 검색된 정보와 이전 대화 내용을 기반으로 프롬프트를 구성합니다. 이 프롬프트는 사용자의 질문에 대한 최적의 답변을 생성하기 위해 AI 모델에 전달됩니다.
4. AI 모델 응답 처리
    - Ollama의 chat()함수를 사용해 선택된 모델로부터 응답을 스트리밍합니다.
    - streamlit의 chat_message 컴포넌트를 사용해 실시간으로 응답을 UI에 표시합니다.
5. 대화 다운로드 및 대화 리셋
    - 대화 다운로드: 사이드바에서 Streamlit의 download_button을 사용하여 대화 기록을 텍스트 파일로 다운로드할 수 있는 기능을 제공합니다.
    - 대화 리셋: 사이드바에서 대화 기록을 초기화하는 버튼을 제공하며, 버튼 클릭 시 session_state를 클리어하고 애플리케이션을 재시작합니다.

## 구현 화면
<p align="center">
  <img src="https://github.com/user-attachments/assets/3b960347-b919-488d-897e-ea0aba16f58e" alt="myecho"/>
</p>

## 추후 보완점
1. 예외 처리 강화:
    - 현재 상황: 빠르게 구현한 결과 예외 처리 부분이 미흡합니다.
    - 추후 계획: 데이터 로딩, 모델 호출, 사용자 입력 등에서 발생할 수 있는 다양한 예외 상황에 대한 처리를 추가하여 사용자 경험을 개선하겠습니다.
2. ChromaDB 임베딩 개선:
    - 현재 상황: ChromaDB가 실행 파일 시작 시 임베딩을 수행하고, 임베딩된 파일이 존재할 경우 이를 재사용하는 방식으로 구현되어 있습니다.
    - 추후 계획: 사용자 편의성을 높이기 위해 화면에서 직접 내용을 입력하고 수정할 수 있는 기능을 추가합니다.
3. 대화 기록 저장 개선:
    - 현재 상황: Streamlit의 session_state를 사용하여 대화 기록을 휘발성으로 저장하고 있습니다.
    - 추후 계획: 대화 기록을 지속적으로 저장하고 관리할 수 있도록 DB를 연동할 계획입니다. 이를 통해 사용자가 이전 대화를 불러오거나 검색할 수있는 기능을 추가하여 사용자 편의성을 높이겠습니다.