import streamlit as st
from langchain_community.llms import Ollama
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain_core.vectorstores import VectorStoreRetriever
import pandas as pd
import os

# ChromaDBì™€ SentenceTransformer ì„ë² ë”© ì´ˆê¸°í™”
embedding_model = HuggingFaceEmbeddings(model_name='snunlp/KR-SBERT-V40K-klueNLI-augSTS')
persist_directory = "./chromadb_data"

# ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ë° ë°ì´í„° ë¡œë“œ
if os.path.exists(persist_directory) and len(os.listdir(persist_directory)) > 0:
    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)
else:
    df = pd.read_csv("./watermoonInfo.csv")
    texts = df['text'].tolist()
    metadatas = [{"text": text} for text in texts]
    vectorstore = Chroma.from_texts(texts, embedding_model, metadatas=metadatas, persist_directory=persist_directory)

# Retriever ì´ˆê¸°í™”
retriever = VectorStoreRetriever(vectorstore=vectorstore)

# Ollama ëª¨ë¸ ì´ˆê¸°í™”
llm = Ollama(model="EEVE-Korean-Instruct-10.8B")

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="MyEcho", page_icon="ğŸ¦¦")
st.title("Chat MyEcho ğŸ¦¦")

# ì‚¬ì´ë“œë°”ì—ì„œ ëŒ€í™” ì œëª© ì…ë ¥
st.sidebar.header("Chat Settings")
chat_title = st.sidebar.text_input("Enter chat title", value="My Chat")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state['messages'] = []
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = ChatMessageHistory()
if 'full_history' not in st.session_state:
    st.session_state['full_history'] = []

# ì±„íŒ… ë©”ì‹œì§€ ì¶œë ¥ í•¨ìˆ˜
for message in st.session_state['messages']:
    st.chat_message(message.role).write(message.content)

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
user_input = st.chat_input("Watermoonë‹˜ì— ëŒ€í•œ ê¶ê¸ˆí•œ ì‚¬í•­ì„ ë¬¼ì–´ë³´ì„¸ìš”! ğŸ‘€")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    user_message = ChatMessage(role="user", content=user_input)
    st.session_state['messages'].append(user_message)
    st.session_state['chat_history'].add_user_message(user_input)
    st.session_state['full_history'].append(user_message)
    st.chat_message("user").write(user_input)

    # í”„ë¡¬í”„íŠ¸ ì„¤ì •
    prompt = ChatPromptTemplate.from_template("""
                ë‚˜ì˜ ì´ë¦„ì€ 'MyEcho'ë¡œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                ì‚¬ìš©ìê°€ ì–´ë–¤ ì§ˆë¬¸ì„ í•˜ë“ , ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ 'Watermoon'ì´ë¼ëŠ” ì‚¬ëŒì— ê´€í•œ ë‹µë³€ì„ ê°„ëµí•˜ê²Œ ì œê³µí•©ë‹ˆë‹¤. 
                ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ì§ˆë¬¸: {query}
                ì•„ë˜ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì •ë³´ë¥¼ ì„ íƒí•˜ì—¬ ë‹µë³€ ì‘ì„±í•´ì£¼ì„¸ìš”:
                {info}
                ë‹µë³€:""")

    # ì‘ë‹µ ìƒì„± ì¤‘ ìƒíƒœ í‘œì‹œ
    response_placeholder = st.empty()

    # ìµœê·¼ ëŒ€í™” 10ê°œ ì¶”ì¶œ (í…œí”Œë¦¿ìš©)
    recent_messages = st.session_state['chat_history'].messages[-10:]

    # ì´ì „ ëŒ€í™”ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    previous_messages = "\n".join(
        f"human: {msg.content}" if i % 2 == 0 else f"ai: {msg.content}"
        for i, msg in enumerate(recent_messages)
    )

    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— 'ìš”ì•½'ì´ë¼ëŠ” ë‹¨ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
    if "ìš”ì•½" in user_input:
        info = ""  # ë²¡í„° DBë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ë¹ˆê°’ìœ¼ë¡œ ì„¤ì •
    else:
        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì •ë³´ ê²€ìƒ‰
        results = retriever.get_relevant_documents(user_input)
        info = "\n".join(result.metadata["text"] for result in results)

    # ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ í•¨ê»˜ ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
    final_prompt = f"{previous_messages}\n\n{prompt.format(query=user_input, info=info)}"

    # LLMì˜ ìŠ¤íŠ¸ë¦¬ë° ê¸°ëŠ¥ ì‚¬ìš©
    response = ""
    for chunk in llm.stream(final_prompt):
        response += chunk
        response_placeholder.write(response)

    # ìµœì¢… ì‘ë‹µ ì €ì¥ ë° í™”ë©´ì— ì¶œë ¥
    assistant_message = ChatMessage(role="assistant", content=response)
    st.session_state['messages'].append(assistant_message)
    st.session_state['chat_history'].add_ai_message(response)
    st.session_state['full_history'].append(assistant_message)
    response_placeholder.empty()
    st.chat_message("assistant").write(response)

# ì‚¬ì´ë“œë°”ì—ì„œ ëŒ€í™” ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
if st.session_state['full_history']:
    chat_history_text = "\n".join(
        f"{msg.role}: {msg.content}" for msg in st.session_state['full_history']
    )
    st.sidebar.download_button(
        label="Download Chat",
        data=chat_history_text,
        file_name=f"{chat_title}.txt",
        mime="text/plain"
    )

# ëŒ€í™” ë¦¬ì…‹ ë²„íŠ¼ êµ¬í˜„
if st.session_state['full_history']:
    if st.sidebar.button("Reset Chat"):
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”, ì„¸ì…˜ ë‚´ ëª¨ë“  ë°ì´í„° ì‚­ì œ
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()